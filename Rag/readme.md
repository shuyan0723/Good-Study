## 为什么要有RAG？
你是一个程序员，你有一个内部文档
你问了问大模型，它不知道你这个文档，它一本正经的胡说八道
回答看似专业实则漏洞百出，这就叫大模型的幻觉

所以你把文档和问题一起发给模型，这时AI就给出了正确的回答
问题似乎解决了，文档越来越大，但答案可能只有一小段
信息一多，AI也找不到重点，我不把整个问题发过去，
执法真正和问题相关的那部分呢？这就是RAG想要解决的问题
## RAG 是什么？
Retrieval-Augmented Generation (RAG)检索、增强、生成
是一种让大模型在回答问题时实时检索外部知识库以增强答案准确性的技术
## 怎么判断文字和用户问题有没有关系呢？
Embedding 模型输入也是一段文字，
但它的输出长度是一个固定长度的数组
text-embedding-3-small 1536
text-embedding-3-large 3072
不管输入的是一句话还是一段话数组长度都是固定的
消息被压缩了，但是意思还在
相似的内容压缩出来的结果也会离得很近

chunking 切块

向量数据库
把问题转化为向量 再从向量数据库里面挑出几段距离最近的内容
再把他们和用户问题一起发给AI模型

有缺陷
1.文章怎么分块？
我是小明，我喜欢北京 文章可能刚好被截断，
前面的小明可能和后面喜欢北京刚好被截断，两个向量距离可能变远
只能减少，不能避免
2.RAG缺乏一个全局的视角？
我叫小明
我想进字节
我要学算法
我在上网课
里面有多少个我字？没有哪句特相关整体都沾点边的问题
改进方案：
 把我都换成老王
 让大模型参与到分块的过程